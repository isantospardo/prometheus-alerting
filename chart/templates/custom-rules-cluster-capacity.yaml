apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    role: alert-rules
  name: prometheus-cern-rules-cluster-capacity
spec:
  groups:
  - name: custom-cern-cluster-capacity.rules
    rules:
    ## Openshift cluster capacity alarms so we know when to add nodes
    - alert: OpenshiftStandardNodesCapacity
      expr: sum(kube_pod_container_resource_requests{resource="memory"} and on (pod) kube_pod_status_phase{phase="Running"}==1 and on (node) kube_node_labels{label_role="standard"})/sum(kube_node_status_allocatable{resource="memory"} and on (node) kube_node_labels{label_role="standard"}) > .65
        OR sum(kube_pod_container_resource_requests{resource="cpu"} and on (pod) kube_pod_status_phase{phase="Running"}==1 and on (node) kube_node_labels{label_role="standard"})/sum(kube_node_status_allocatable{resource="cpu"} and on (node) kube_node_labels{label_role="standard"}) > .65
      for: 1d
      labels:
        severity: important
      annotations:
        description: We want to remain able to schedule all applications when losing all nodes in a given availability zone,
          i.e. 1/3 of the nodes. New nodes should be installed when the ratio of requested resources
          to total capacity exceeds 65% for CPU or memory.
        summary: Standard node capacity is insufficient for safe operation

    - alert: OpenshiftStandardNodesAvailableMemory
      expr: sum((label_replace(node_memory_MemAvailable - 0.1 * node_memory_MemTotal,
        "node", "$1", "kubernetes_pod_node_name", "(.*)") and ON(node) kube_node_status_condition{condition="Ready", status="true"}
        == 1 and ON(node) kube_node_spec_unschedulable != 1 and ON(node) kube_node_labels{label_role="standard"}))
        / sum(kube_node_status_allocatable{resource="memory"} and ON(node) kube_node_status_condition{condition="Ready", status="true"}
        == 1 and ON(node) kube_node_spec_unschedulable != 1 and ON(node) kube_node_labels{label_role="standard"} == 1)
        < 0.05
      for: 30m
      labels:
        severity: important
      annotations:
        description: Memory on ready+schedulable standard nodes is getting full. Pods
          may be evicted or fail to be scheduled. This typically indicates that too
          many nodes are down or under maintenance.
        summary: Currently available memory on ready+schedulable standard nodes is critically
          low

    - alert: OpenshiftStandardNodesAllocatableMemory
      expr: sum(kube_pod_container_resource_requests{resource="memory"} and ON(pod) kube_pod_status_phase{phase="Running"}
        == 1 and ON(node) kube_node_labels{label_role="standard"} == 1) / sum(kube_node_status_allocatable{resource="memory"}
        and ON(node) kube_node_status_condition{condition="Ready", status="true"} == 1 and ON(node) kube_node_spec_unschedulable
        != 1 and ON(node) kube_node_labels{label_role="standard"} == 1) > 0.95
      for: 15m
      labels:
        severity: critical
      annotations:
        description: Allocatable memory on ready+schedulable standard nodes is getting
          completely used. Pods may fail to be scheduled. This typically indicates that
          too many nodes are down or under maintenance.
        summary: Currently allocatable memory on ready+schedulable standard nodes is
          critically low

    - alert: OpenshiftStandardNodesAllocatableCpu
      expr: sum(kube_pod_container_resource_requests{resource="cpu"} and ON(pod) kube_pod_status_phase{phase="Running"}
        == 1 and ON(node) kube_node_labels{label_role="standard"} == 1) / sum(kube_node_status_allocatable{resource="cpu"}
        and ON(node) kube_node_status_condition{condition="Ready", status="true"} == 1 and ON(node) kube_node_spec_unschedulable
        != 1 and ON(node) kube_node_labels{label_role="standard"} == 1) > 0.95
      for: 15m
      labels:
        severity: critical
      annotations:
        description: Allocatable CPU on ready+schedulable standard nodes is getting
          completely used. Pods may fail to be scheduled. This typically indicates that
          too many nodes are down or under maintenance.
        summary: Currently allocatable CPU on ready+schedulable standard nodes is critically
          low
