apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    role: alert-rules
  name: prometheus-cern-rules-applications
  namespace: openshift-monitoring
spec:
  groups:
  - name: custom-cern-applications.rules
    rules:
    ## Detection of misbehaving applications affecting cluster
    - alert: OpenShiftTerminatedPodGC
      expr: count(kube_pod_status_phase{phase!="Pending",phase!="Running",phase!="Unknown"}
        == 1) >= 1200
      for: 1h
      labels:
        severity: important
      annotations:
        description: Terminated pods are being garbage-collected. This could be a problem
          with a project creating pods at a fast rate and not cleaning them up (e.g.
          a cronjob with restartPolicy=Never, see CIPAAS-354). Or, as the number of projects grows,
          it may be a normal situation and we kust need to increase the pod GC limit.
        recovery_action: >
          Use `oc get pods --all-namespaces | grep -v Running | awk '{print $1}' | uniq -c | sort -n`
          to see if a project is creating a large number of non-running pods.

          Case 1: if there seems to be such a project, most likely it is a Job or CronJob with `restartPolicy=Never`.
          Set restartPolicy to OnFailure and notify owner of why this is a better setting.
          See https://its.cern.ch/jira/browse/CIPAAS-354

          Case 2: all projects have resonable amount of pods, we hit the limit because of the number of projects.
          Then increase the limit as per https://cern.ch/openshiftdocs/Operations/Cluster_Admin/updatePodGCLimit/
        summary: Check if pods are being garbage-collected
